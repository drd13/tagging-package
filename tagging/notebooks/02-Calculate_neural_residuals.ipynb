{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Residuals\n",
    "\n",
    "This notebook calculates and pickles residuals for spectral fits using neural network. These results are then visualized in notebook 03 and can be used to reproduce a figure in the paper.\n",
    "\n",
    "By setting ```architecture=fader``` or ```architecture=factor``` it is possible to either run results for the factorDis or for the faderDis method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "#from tagging.src.datasets import ApogeeDataset\n",
    "#from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward\n",
    "\n",
    "sys.path.insert(0,'/share/splinter/ddm/taggingProject/taggingClean/')\n",
    "from src.datasets import ApogeeDataset\n",
    "from src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "from tagging.src.utils import get_batch, invert_x,get_xdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 9\n",
    "n_bins = 7751 \n",
    "n_conditioned = 3\n",
    "architecture = \"fader\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we next load the data and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/share/splinter/ddm/taggingProject/taggingClean/data/final/train/spectra_noiseless.pd\")\n",
    "\n",
    "\n",
    "dataset = ApogeeDataset(data,n_bins)\n",
    "evaluation_loader = torch.utils.data.DataLoader(dataset = dataset[0:18],\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle = False,\n",
    "                                     drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == \"fader\":\n",
    "    conditioning_autoencoder = torch.load(\"/share/splinter/ddm/taggingProject/taggingClean/models/faderDis4wZ/runs/100/adN7214I4000\",map_location=device)\n",
    "elif architecture == \"factor\":\n",
    "    conditioning_autoencoder = torch.load(\"/share/splinter/ddm/taggingProject/taggingClean/models/wasDiswZ/runs/0/wganI6000\",map_location=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load the spectra and associated parameters for the stars we will visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1,u_test1,v_test1,idx_test1 = get_batch(0,n_batch,dataset)\n",
    "x_test2,u_test2,v_test2,idx_test2 = get_batch(25000,n_batch,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we next evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,z1 = conditioning_autoencoder(x_test1,u_test1[:,0:n_conditioned],train_decoder=False)\n",
    "_,z2 = conditioning_autoencoder(x_test2,u_test2[:,0:n_conditioned],train_decoder=False)\n",
    "x1_pred,_ = conditioning_autoencoder(z1,u_test1[:,0:n_conditioned],train_encoder=False)\n",
    "x1_pred_swp,_ = conditioning_autoencoder(z1,u_test2[:,0:n_conditioned],train_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = invert_x(x_test1)\n",
    "x_test2 = invert_x(x_test2)\n",
    "x1_pred = invert_x(x1_pred)\n",
    "x1_pred_swp = invert_x(x1_pred_swp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "We can now plot the visualized stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = get_xdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "lw = 1\n",
    "ls = (0, (5, 5))\n",
    "\n",
    "i=0\n",
    "n_start = 0\n",
    "n_end = 256\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1,sharex=True,gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(xdata[n_start:n_end],x_test1[i].detach().cpu().numpy()[n_start:n_end],linewidth=lw,label=\"$x_{1}$\",c=\"b\")\n",
    "ax1.plot(xdata[n_start:n_end],x_test2[i].detach().cpu().numpy()[n_start:n_end],linewidth=lw,label=\"$x_{2}$\",c=\"darkorange\") \n",
    "\n",
    "\n",
    "ax2.plot(xdata[n_start:n_end],x1_pred_swp[i].detach().cpu().numpy()[n_start:n_end],linewidth=lw,label=\"$D(E(x_{1},u_{1}),u_{2})$\",c=\"b\")\n",
    "ax2.plot(xdata[n_start:n_end],x_test2[i].detach().cpu().numpy()[n_start:n_end],linewidth=lw,label=\"$x_{2}$\",c=\"darkorange\")\n",
    "\n",
    "\n",
    "fig.text(0.05, 0.62, 'flux', va='center', rotation='vertical',fontsize=20)\n",
    "\n",
    "res1 = x1_pred_swp[i]-x_test2[i]\n",
    "res1 = res1.detach().cpu().numpy()\n",
    "ax3.plot(xdata[n_start:n_end],res1[n_start:n_end],linewidth=lw,label=\"$D(E(x_{1},u_{1}),u_{2})-x_{2}$\",c=\"b\")\n",
    "\n",
    "\n",
    "\n",
    "fig.text(0.05, 0.25, 'residuals', va='center', rotation='vertical',fontsize=16)\n",
    "\n",
    "fig.text(0.13,0.915,\"a) FaderDis\".format(*data[\"params\"][i][0:3]+data[\"params\"][i+25000][0:3]),va='center', rotation='horizontal',fontsize=16)\n",
    "\n",
    "fig.text(0.13,0.965,\"Star $x_1$: Teff= {} , logg = {}, [Fe/H]= {:.2g}         Star $x_2$: Teff= {} , logg = {}, [Fe/H]= {:.2g}\".format(*data[\"params\"][i][0:3]+data[\"params\"][i+25000][0:3]),va='center', rotation='horizontal',fontsize=16)\n",
    "\n",
    "\n",
    "ax1.set_ylim(0.6,1.0)\n",
    "ax2.set_ylim(0.6,1.0)\n",
    "ax3.set_ylim(-0.015,0.015)\n",
    "\n",
    "fig.set_size_inches(14.5, 6.5)\n",
    "plt.xlim(xdata[n_start],xdata[n_end])\n",
    "plt.xlabel(r\"Wavelength($\\AA$)\",fontsize=24)\n",
    "\n",
    "yticks1 = ax1.yaxis.get_major_ticks()\n",
    "yticks1[0].set_visible(False)\n",
    "\n",
    "yticks2 = ax2.yaxis.get_major_ticks()\n",
    "yticks2[0].set_visible(False)\n",
    "\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
