{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Modification\n",
    "\n",
    "This notebook relates to modifying the decoder used. I want to switch to a neural network that processes every single pixel bin in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tagging.paths import path_dataset\n",
    "from tagging.src.datasets import ApogeeDataset\n",
    "from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch =32\n",
    "n_latent = 22\n",
    "n_bins = 500\n",
    "n_hidden = 10\n",
    "latent = torch.ones(n_batch,n_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_latent = latent.repeat(1,n_bins)\n",
    "repeated_latent = repeated_latent.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_latent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the parralel network through a convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(in_channels=n_latent * n_bins, out_channels= n_hidden * n_bins, kernel_size=1, groups=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(repeated_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the parralel decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelDecoder(nn.Module):\n",
    "    def __init__(self,n_bins=100,n_hidden = 10,n_latent=22,activation=nn.LeakyReLU()):\n",
    "        super(ParallelDecoder, self).__init__()\n",
    "        self.n_bins = n_bins\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_latent = n_latent\n",
    "        self.n_output = 1\n",
    "        self.activation = activation\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.n_latent * self.n_bins, out_channels= self.n_hidden * self.n_bins, kernel_size=1, groups=self.n_bins)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.n_hidden * self.n_bins, out_channels= self.n_hidden * self.n_bins, kernel_size=1, groups=self.n_bins)\n",
    "        self.conv3 = nn.Conv1d(in_channels=self.n_hidden * self.n_bins, out_channels= self.n_output * self.n_bins, kernel_size=1, groups=self.n_bins)\n",
    "        \n",
    "        \n",
    "    def forward(self, latent):\n",
    "        repeated_latent = latent.repeat(1,self.n_bins)\n",
    "        repeated_latent = repeated_latent.unsqueeze(2)\n",
    "        #print(f\"repeated_latent:{repeated_latent.shape}\")\n",
    "\n",
    "        hidden1 = self.activation(self.conv1(repeated_latent))\n",
    "        #print(f\"hidden1:{hidden1.shape}\")\n",
    "\n",
    "        hidden2 = self.activation(self.conv2(hidden1))\n",
    "        #print(f\"hidden2:{hidden2.shape}\")\n",
    "\n",
    "        output = self.conv3(hidden2)\n",
    "        #print(f\"output:{output.shape}\")\n",
    "        output = torch.squeeze(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder,n_bins = None):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_bins = n_bins\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, x,train_encoder=True,train_decoder=True):\n",
    "        latent=None\n",
    "        output=None\n",
    "        if train_encoder:\n",
    "            x= self.encoder(x)\n",
    "            latent = x\n",
    "        if train_decoder:\n",
    "            x = self.decoder(x)\n",
    "            output = x\n",
    "        return output,latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = ParallelDecoder(n_bins=n_bins,n_hidden=n_hidden,n_latent=n_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test an autoencoder with the new decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 5000\n",
    "n_batch = 64\n",
    "n_z = 20\n",
    "n_cat = 30\n",
    "n_hidden = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(path_dataset)\n",
    "dataset = ApogeeDataset(data[:50000],n_bins)\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle= True,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward([n_bins,512,128,32,n_z],activation=nn.SELU()).to(device)\n",
    "decoder = ParallelDecoder(n_bins=n_bins,n_hidden=n_hidden,n_latent=n_z).to(device)\n",
    "autoencoder = Autoencoder(encoder,decoder,n_bins=n_bins).to(device)\n",
    "\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer_autoencoder = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELU\n",
    "for i in range(100):\n",
    "\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        err_tot = err_pred\n",
    "\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        if j%10==0:\n",
    "            print(f\"epoch:{i},err:{err_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELU\n",
    "for i in range(100):\n",
    "\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        err_tot = err_pred\n",
    "\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        if j%10==0:\n",
    "            print(f\"epoch:{i},err:{err_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid\n",
    "for i in range(100):\n",
    "\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        err_tot = err_pred\n",
    "\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        if j%10==0:\n",
    "            print(f\"epoch:{i},err:{err_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeakyReLU\n",
    "for i in range(100):\n",
    "\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        err_tot = err_pred\n",
    "\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        if j%10==0:\n",
    "            print(f\"epoch:{i},err:{err_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward([n_bins,512,128,32,n_z],activation=nn.sigmoid()).to(device)\n",
    "decoder = ParallelDecoder(n_bins=n_bins,n_hidden=n_hidden,n_latent=n_z).to(device)\n",
    "autoencoder = Autoencoder(encoder,decoder,n_bins=n_bins).to(device)\n",
    "\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer_autoencoder = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred.shape\n",
    "n_bins= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward([n_bins,512,128,32,n_z],activation=nn.LeakyReLU()).to(device)\n",
    "decoder = Feedforward([n_z,32,128,512,n_bins],activation=nn.LeakyReLU()).to(device)\n",
    "\n",
    "autoencoder = Autoencoder(encoder,decoder,n_bins=n_bins).to(device)\n",
    "\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer_autoencoder = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        err_tot = err_pred\n",
    "\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        if j%100==0:\n",
    "            print(f\"err:{err_tot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    x_pred,z = autoencoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    x_pred,z = autoencoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
