{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abundance Estimation\n",
    "\n",
    "This notebook relates to directly obtaining abundances from the disentangled neural networks\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tagging.paths import path_dataset\n",
    "from tagging.src.datasets import ApogeeDataset\n",
    "from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward,ParallelDecoder\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 1000\n",
    "n_batch = 64\n",
    "n_z = 20\n",
    "n_cat = 30\n",
    "n_hidden = 10\n",
    "lr = 0.0001\n",
    "n_conditioned = 2\n",
    "loss_ratio = 10e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(path_dataset)\n",
    "dataset = ApogeeDataset(data[:50000],n_bins)\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle= True,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward([n_bins+n_conditioned,512,128,32,n_z],activation=nn.SELU()).to(device)\n",
    "decoder = ParallelDecoder(n_bins=n_bins,n_hidden=n_hidden,n_latent=n_z+n_conditioned,activation=nn.SELU()).to(device)\n",
    "autoencoder = ConditioningAutoencoder(encoder,decoder,n_bins=n_bins).to(device)\n",
    "\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer_autoencoder = torch.optim.Adam(autoencoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pred_u0_given_v = Feedforward([n_z+1,512,256,n_cat],activation=nn.SELU()).to(device)\n",
    "pred_u1_given_v = Feedforward([n_z+1,512,256,n_cat],activation=nn.SELU()).to(device)\n",
    "\n",
    "\n",
    "optimizer_u0 = torch.optim.Adam(pred_u0_given_v.parameters(), lr=lr)\n",
    "optimizer_u1 = torch.optim.Adam(pred_u1_given_v.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.full((n_batch,2), 0.0, device=device)\n",
    "ones = torch.full((n_batch,2),1.0,device=device)\n",
    "noise = 100\n",
    "noise_matrix = torch.empty(50000,n_bins).normal_(mean=0,std=1/noise).to(device)*4 #We initialize one noisy version of every datapoint and always use the same noise. This was found to work better (but not fully understood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(100):\n",
    "    for j,(x,u,v,idx) in enumerate(loader):\n",
    "\n",
    "        u_cat = ((u+1)*n_cat/2).long()\n",
    "        u_cat[u_cat==n_cat]=n_cat-1\n",
    "\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        \n",
    "        x_pred,z = autoencoder(x,u[:,0:2].detach())\n",
    "        err_pred = loss(x_pred,x)  \n",
    "        z0 = torch.cat((z,u[:,1:2]),1)\n",
    "        z1 = torch.cat((z,u[:,0:1]),1)\n",
    "\n",
    "        \n",
    "        z0 = torch.cat((z,u[:,1:2]),1)\n",
    "        z1 = torch.cat((z,u[:,0:1]),1)\n",
    "        u0_pred = pred_u0_given_v(z0)  \n",
    "        u1_pred = pred_u1_given_v(z1)  \n",
    "      \n",
    "        \n",
    "        \n",
    "        err_u0 = loss2(u0_pred,u_cat[:,0])\n",
    "        err_u1 = loss2(u1_pred,u_cat[:,1])\n",
    "        err_tot = err_pred-loss_ratio*err_u0-loss_ratio*err_u1 #agrregated loss\n",
    "        \n",
    "\n",
    "        err_tot.backward(retain_graph=True)\n",
    "        optimizer_autoencoder.step()        \n",
    "        optimizer_u0.zero_grad()\n",
    "        err_u0.backward(retain_graph=True)\n",
    "        optimizer_u0.step()\n",
    "        optimizer_u1.zero_grad()\n",
    "        err_u1.backward()\n",
    "        optimizer_u1.step()\n",
    "        if j%10==0:\n",
    "            print(\"epoch:{},tot:{},err:{},err_u0:{},er_u1:{}\".format(i,err_tot,err_pred,err_u0,err_u1))\n",
    "            \n",
    "torch.save(autoencoder.state_dict(), \"conditional_parallel_decoder.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), \"conditional_parallel_decoder.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(u0_pred,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder, \"conditional_parallel_decoder.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_state_dict(torch.load(\"conditional_parallel_decoder.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
