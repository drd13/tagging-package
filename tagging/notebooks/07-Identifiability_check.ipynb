{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifiability check\n",
    "\n",
    "We check if abundances are recoverable up to a linear transformation (the answer is more or less but more than less yes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from tagging.src.datasets import ApogeeDataset\n",
    "from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "sys.path.insert(0,'/share/splinter/ddm/taggingProject/taggingClean/')\n",
    "from src.datasets import ApogeeDataset\n",
    "from src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/share/splinter/ddm/taggingProject/taggingRepo/data/processed/spectra_noiseless.pd\")\n",
    "noisy_data = pd.read_pickle(\"/share/splinter/ddm/taggingProject/taggingClean/data/final/train/spectra_SN_100.pd\")\n",
    "val_data = pd.read_pickle(\"/share/splinter/ddm/taggingProject/taggingRepo/data/processed/spectra_noiseless_val.pd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 7751\n",
    "n_batch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ApogeeDataset(data,n_bins)\n",
    "noisy_dataset = ApogeeDataset(noisy_data,n_bins)\n",
    "val_dataset = ApogeeDataset(val_data,n_bins)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle = False,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load the model we want to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_file = \"../../outputs/results_fader/run5/adN7214I1600\"\n",
    "model_file = \"/share/splinter/ddm/taggingProject/taggingRepo/outputs/results_fader/expandedLatent/adN7214I1600\"\n",
    "#model_file = \"/share/splinter/ddm/taggingProject/taggingClean/models/wasDis/runs/0/wganI5400\"\n",
    "\n",
    "conditioning_autoencoder = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z(idx,dataset):\n",
    "    _,z = conditioning_autoencoder(dataset[idx][0].unsqueeze(0),dataset[idx][1][0:2].unsqueeze(0))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the abundances and latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.params.values[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundances_array = np.array([row for row in data.abundances.values])\n",
    "abundances_val_array = np.array([row for row in val_data.abundances.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array =  np.array([row[2:] for row in data.params.values])\n",
    "abundances_array = np.concatenate((abundances_array,params_array),axis=1)\n",
    "params_val_array =  np.array([row[2:] for row in val_data.params.values])\n",
    "abundances_val_array = np.concatenate((abundances_val_array,params_val_array),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_array = np.array([get_z(i,dataset).detach().cpu().numpy() for i in range(2000)]).squeeze()\n",
    "z_val_array = np.array([get_z(i,val_dataset).detach().cpu().numpy() for i in range(2000)]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation\n",
    "\n",
    "We recenter (make mean=0) both the latents ```z_array``` and the  abundances ```abundances_arrat```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_calibrated = (z_array- np.mean(z_array,axis=0)).T\n",
    "z_val_calibrated = (z_val_array- np.mean(z_array,axis=0)).T\n",
    "abundances_calibrated = (abundances_array-np.mean(abundances_array,axis=0))[:2000].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we learn a matrix corresponding to a linear transformation between both spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_calibrated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_est = np.linalg.pinv(z_calibrated.T).dot(abundances_calibrated.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_est.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_est =np.dot(abundances_calibrated,np.linalg.pinv(z_calibrated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundances_calibrated_est = np.dot(W_est,z_calibrated)\n",
    "abundances_est = (abundances_calibrated_est.T+np.mean(abundances_array,axis=0)).T #re-add the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundances_calibrated_val_est = np.dot(W_est,z_val_calibrated)\n",
    "abundances_val_est = (abundances_calibrated_val_est.T+np.mean(abundances_array,axis=0)).T #re-add the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements= [\"[N/Fe]\",\"[O/Fe]\",\"[Na/Fe]\",\"[Mg/Fe]\",\"[Al/Fe]\",\"[Si/Fe]\",\"[S/Fe]\",\"[K/Fe]\",\"[Ca/Fe]\",\"[Ti/Fe]\",\"[V/Fe]\",\"[Mn/Fe]\",\"[Ni/Fe]\",\"[P/Fe]\",\"[Cr/Fe]\",\"[Co/Fe]\",\"[Rb/Fe]\",\"[Fe/H]\",r\"[$\\alpha$\\Fe]\",\"[C/Fe]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now plot the abundances estimated from the latent ```abundance_est``` and compare them to the true abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(20):\n",
    "    plt.title(f\"element:{elements[idx]}\")\n",
    "    plt.scatter(abundances_est[idx,0:2000],abundances_array.T[idx,0:2000])\n",
    "    plt.xlabel(\"estimated\")\n",
    "    plt.ylabel(\"true\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(20):\n",
    "    plt.title(f\"element:{elements[idx]}\")\n",
    "    plt.scatter(abundances_val_est[idx,0:2000],abundances_val_array.T[idx,0:2000])\n",
    "    plt.xlabel(\"estimated\")\n",
    "    plt.ylabel(\"true\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the actual information content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loader,v_index,train_u=False):\n",
    "    \"\"\"\n",
    "    loader: \n",
    "        pytorch dataset loader\n",
    "    v_index: int\n",
    "        index of input array to train\n",
    "    train_v: bool\n",
    "        whether to train using the v_index (True) or the u_index (False)\n",
    "    \"\"\"\n",
    "    n_z = z_calibrated.shape[0]\n",
    "    feedforward = Feedforward([n_z,512,256,128,1],activation=nn.SELU()).to(device)\n",
    "    loss = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(feedforward.parameters(),lr=0.0001)\n",
    "    for i in range(6):\n",
    "        for j,(x,u,v,idx) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            _,z = conditioning_autoencoder(x,u[:,0:2])\n",
    "            pred = feedforward(z.detach())\n",
    "            if train_u:\n",
    "                err = loss(pred,u[:,v_index:v_index+1])    \n",
    "            else:\n",
    "                err = loss(pred,v[:,v_index:v_index+1])\n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "            if j%100==0:\n",
    "                print(f\"epoch:{i},err:{err}\")\n",
    "    return feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = []\n",
    "for i in range(17):\n",
    "    networks.append(train_network(loader,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,5):\n",
    "    networks.append(train_network(loader,i,train_u=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v(z,network):\n",
    "    z_tensor = torch.tensor(z).to(device)\n",
    "    v_tensor = network(z_tensor)\n",
    "    return v_tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(20):\n",
    "    plt.title(f\"element:{elements[idx]}\")\n",
    "    v_net_array = get_v(z_array,networks[idx])\n",
    "    v_net_array = (max(abundances_array[:,idx])-min(abundances_array[:,idx]))*(v_net_array+1)/2+min(abundances_array[:,idx])\n",
    "    plt.scatter(v_net_array,abundances_array.T[idx,0:2000],s=0.5,alpha=0.5,label=\"optimal\")\n",
    "    plt.scatter(abundances_est[idx,0:2000],abundances_array.T[idx,0:2000],s=0.5,alpha=0.5,label=\"linear\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"estimated\")\n",
    "    plt.ylabel(\"true\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def draw_figure(ax,idx):\n",
    "    ax.set_title(f\"{elements[idx]}\")\n",
    "    v_net_array = get_v(z_array,networks[idx])\n",
    "    v_net_array = (max(abundances_array[:,idx])-min(abundances_array[:,idx]))*(v_net_array+1)/2+min(abundances_array[:,idx])\n",
    "    ax.scatter(abundances_array.T[idx,0:2000],v_net_array,s=0.5,alpha=0.5,label=\"non-linear\")\n",
    "    ax.scatter(abundances_array.T[idx,0:2000],abundances_est[idx,0:2000],s=0.5,alpha=0.5,label=\"linear\")\n",
    "    lgnd = ax.legend()\n",
    "    lgnd.legendHandles[0]._sizes = [30]\n",
    "    lgnd.legendHandles[1]._sizes = [30]\n",
    "    ax.set_ylabel(\"estimated (dex)\")\n",
    "    ax.set_xlabel(\"true (dex)\")\n",
    "    \n",
    "def make_canvas():\n",
    "    fig = plt.figure(constrained_layout=True,figsize=[14,17.5])\n",
    "    spec = gridspec.GridSpec(ncols=4, nrows=5, figure=fig)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            fig_ax = fig.add_subplot(spec[i, j])\n",
    "            #fig_ax.set_axis_off()\n",
    "            draw_figure(fig_ax,i+j*4)\n",
    "    for i,j in enumerate([0,2]): \n",
    "        fig_ax = fig.add_subplot(spec[4, i])\n",
    "        draw_figure(fig_ax,17+j)\n",
    "\n",
    "    return fig\n",
    "            \n",
    "fig = make_canvas()\n",
    "fig.savefig(\"latent_interpretabilty.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? plt.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
